version: '3.8'
services:
  spark-master:
    image: custom-spark-rdkit:latest
    container_name: spark-master
    ports:
      - '8080:8080'
      - '7077:7077'
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    hostname: spark-master
    networks:
      - spark-net
    volumes:
      - ./data_share:/opt/spark/data
      - ./data_share:/opt/airflow/data

  spark-worker-1:
    image: custom-spark-rdkit:latest
    container_name: spark-worker-1
    environment:
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    hostname: spark-worker-1
    networks:
      - spark-net
    volumes:
      - ./data_share:/opt/spark/data
      - ./data_share:/opt/airflow/data

  spark-worker-2:
    image: custom-spark-rdkit:latest
    container_name: spark-worker-2
    environment:
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    hostname: spark-worker-2
    networks:
      - spark-net
    volumes:
      - ./data_share:/opt/spark/data
      - ./data_share:/opt/airflow/data

  spark-worker-3:
    image: custom-spark-rdkit:latest
    container_name: spark-worker-3
    environment:
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    hostname: spark-worker-3
    networks:
      - spark-net
    volumes:
      - ./data_share:/opt/spark/data
      - ./data_share:/opt/airflow/data

  airflow:
    image: my-airflow-spark:latest
    container_name: airflow-standalone
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - _AIRFLOW_DB_MIGRATE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_PASSWORD=admin
      - AIRFLOW_CONN_SPARK_DEFAULT=spark://spark%3A%2F%2Fspark-master:7077
    ports:
      - "8081:8080"
    command: bash -c "airflow db migrate && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com 2>/dev/null || true && airflow webserver -p 8080 & airflow scheduler"
    depends_on:
      - spark-master
    volumes:
      - airflow_db:/opt/airflow
      - ./dags:/opt/airflow/dags
      - ./data_share:/opt/airflow/data
    networks:
      - spark-net

volumes:
  airflow_db:

networks:
  spark-net:
    driver: bridge
